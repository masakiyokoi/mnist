{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2層パーセプトロン "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('~/common')\n",
    "from common.functions import softmax,cross_entropy_error  #softmax(活性化関数),エントロピー二乗誤差(誤差関数)\n",
    "from common.gradient import numerical_gradient #numerical_gradient(パラメータの更新、勾配)\n",
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重みWはガウス分布で初期化,バイアスは0で初期化\n",
    "class Twolayer:\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,output_size,weight_init_std = 0.01):\n",
    "        \n",
    "        #重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size,hidden_size) #学習率(0.01)*ランダムに生成された行列(input_size×hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size) #(1×hidden_size)、要素が0の1次元配列\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size,output_size) #行列の形が違う。\n",
    "        self.params['b2'] = np.zeros(output_size) #行列の形が違う。\n",
    "    \n",
    "    def convert_t(self,t_train):\n",
    "   \n",
    "        t = np.zeros((t_train.shape[0],10))\n",
    "        for i in range(t_train.shape[0]):\n",
    "            label = t_train[i] #5\n",
    "            t[i][label-1] = 1\n",
    "        \n",
    "        return t\n",
    "        \n",
    "    \n",
    "    def predict(self,x): #出力\n",
    "        W1,W2 = self.params['W1'],self.params['W2']\n",
    "        b1,b2 = self.params['b1'],self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x,W1) + b1\n",
    "        z1 = softmax(a1)\n",
    "        a2 = np.dot(z1,W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "         \n",
    "    \n",
    "    def loss(self,x,t): #lossの算出 by cross_entropy_error\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        \n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis = 0)\n",
    "        t = np.argmax(t,axis = 0)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def solve_gradient(self,x,t):\n",
    "        loss_W = lambda W:self.loss(x,t) #入力と正解ラベルのlossを求める無名関数loss_Wの作成\n",
    "        \n",
    "        grads = {}\n",
    "        \n",
    "        grads['W1'] = numerical_gradient(loss_W,self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W,self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W,self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W,self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.43431311e-03 -9.50479882e-03 -1.73524496e-02 ...  1.20079467e-02\n",
      "  -1.40627534e-02  9.28828438e-04]\n",
      " [-1.51936752e-02 -2.38137038e-02 -7.50697564e-03 ...  1.29086827e-02\n",
      "  -2.20105639e-02  4.17997485e-03]\n",
      " [-1.07545648e-02  8.66533582e-03  3.35433763e-03 ... -3.66920043e-03\n",
      "   3.76652798e-03 -1.32429462e-02]\n",
      " ...\n",
      " [-2.75354024e-03 -1.99372833e-02 -9.92409642e-03 ... -1.63471860e-03\n",
      "  -1.01797631e-02 -2.04050267e-02]\n",
      " [-9.14702428e-03  4.00698222e-04 -1.83537789e-02 ...  1.33834253e-02\n",
      "   1.43903290e-02  4.75340859e-03]\n",
      " [ 7.45297221e-03 -2.27098257e-03  5.81777337e-04 ...  2.67391523e-04\n",
      "   1.06502510e-05  3.35984345e-02]]\n"
     ]
    }
   ],
   "source": [
    "from load_mnist import *\n",
    "x_train,t_train = load_mnist('',kind = 'train')\n",
    "\n",
    "net = Twolayer(input_size = 784,hidden_size = 100,output_size = 10)\n",
    "\n",
    "x = x_train[0]\n",
    "#print(x.shape)\n",
    "\n",
    "t = net.convert_t(t_train)\n",
    "t = t[0]\n",
    "\n",
    "print(net.params['W1'])\n",
    "#net.accuracy(x,t)\n",
    "grads = net.solve_gradient(x,t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.70854458e-04,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        7.20495130e-02,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.72409644e+01, -4.01516376e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.73093862e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grads['W1'].shape)\n",
    "np.dot(x,grads['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

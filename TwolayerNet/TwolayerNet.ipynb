{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2層パーセプトロン "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('../common')\n",
    "from functions import softmax,cross_entropy_error  #softmax(活性化関数),エントロピー二乗誤差(誤差関数)\n",
    "from gradient import numerical_gradient #numerical_gradient(パラメータの更新、勾配)\n",
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重みWはガウス分布で初期化,バイアスは0で初期化\n",
    "class Twolayer:\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,output_size,weight_init_std = 0.01):\n",
    "        \n",
    "        #重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size,hidden_size) #学習率(0.01)*ランダムに生成された行列(input_size×hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size) #(1×hidden_size)、要素が0の1次元配列\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size,output_size) #行列の形が違う。\n",
    "        self.params['b2'] = np.zeros(output_size) #行列の形が違う。\n",
    "    \n",
    "    def convert_t(self,t_train):\n",
    "   \n",
    "        t = np.zeros((t_train.shape[0],10))\n",
    "        for i in range(t_train.shape[0]):\n",
    "            label = t_train[i] #5\n",
    "            t[i][label-1] = 1\n",
    "        \n",
    "        return t\n",
    "        \n",
    "    \n",
    "    def predict(self,x): #出力\n",
    "        W1,W2 = self.params['W1'],self.params['W2']\n",
    "        b1,b2 = self.params['b1'],self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x,W1) + b1\n",
    "        z1 = softmax(a1)\n",
    "        a2 = np.dot(z1,W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "         \n",
    "    \n",
    "    def loss(self,x,t): #lossの算出 by cross_entropy_error\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        \n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis = 0)\n",
    "        t = np.argmax(t,axis = 0)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self,x,t):\n",
    "        loss_W = lambda W:self.loss(x,t) #入力と正解ラベルのlossを求める無名関数loss_Wの作成\n",
    "        \n",
    "        grads = {}\n",
    "        \n",
    "        grads['W1'] = numerical_gradient(loss_W,self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W,self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W,self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W,self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.61122470e-03 -9.33415479e-03 -6.48594949e-03 ... -1.50157909e-02\n",
      "  -1.53690619e-02 -5.59262568e-05]\n",
      " [ 1.44443395e-02  5.87905029e-03 -1.11603076e-02 ...  1.00384066e-02\n",
      "   4.64626409e-03  8.50008508e-03]\n",
      " [-3.08371619e-02  2.12653696e-02 -3.07819240e-03 ...  2.42791698e-03\n",
      "   2.10412856e-02  2.24711881e-03]\n",
      " ...\n",
      " [-6.31815248e-04  8.92846199e-03 -7.89362814e-04 ... -6.82494498e-03\n",
      "  -6.56279170e-04  4.95765927e-03]\n",
      " [-9.69882845e-03 -5.88531480e-03 -1.96360144e-03 ... -9.56372081e-04\n",
      "   7.67681548e-03  7.99854173e-03]\n",
      " [ 1.20214322e-03 -3.27536837e-03  7.19332051e-04 ... -5.17370443e-03\n",
      "   5.40332208e-03  9.29475782e-03]]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../')\n",
    "from load_mnist import *\n",
    "x_train,t_train = load_mnist('',kind = 'train')\n",
    "\n",
    "net = Twolayer(input_size = 784,hidden_size = 100,output_size = 10)\n",
    "\n",
    "x = x_train[0]\n",
    "#print(x.shape)\n",
    "\n",
    "t = net.convert_t(t_train)\n",
    "t = t[0]\n",
    "\n",
    "print(net.params['W1'])\n",
    "#net.accuracy(x,t)\n",
    "grads = net.numerical_gradient(x,t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
